{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from experiments.data_gen import PascalVOCDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.callbacks.metric_callbacks import MAPCallback\n",
    "from model.callbacks.save_callback import SaveModel\n",
    "from model.callbacks.scheduler import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.losses import BCE, PartialBCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config_utils\n",
    "from experiments.launch import parse_options_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.utils.config import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_options_file('/home/caleml/partial-labels/config/pv_baseline50_sgd_448lrs.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From http://cedric.cnam.fr/vertigo/Cours/ml2/tpDeepLearning5.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 architecture & its weights\n",
    "# imagenet_model = ResNet50(include_top=True, weights='imagenet')\n",
    "# model.layers.pop()\n",
    "# Modify top layers\n",
    "# x = model.layers[-1].output\n",
    "# x = Dense(data_generator_train.nb_classes, activation='sigmoid', name='predictions')(x)\n",
    "# model = Model(inputs=model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagenet only model (no finetuning)\n",
    "model = ResNet50(include_top=True, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers.pop().pop()\n",
    "model = Model(inputs=model.input,outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(lr, momentum=0.9), metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/'\n",
    "data_generator_train = PascalVOCDataGenerator('trainval', data_dir, prop=prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_train = PascalVOCDataGenerator('trainval', data_dir, force_old=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "generator = data_generator_train.flow(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilisation des matrices contenant les Deep Features et les labels\n",
    "X_train = np.zeros((len(data_generator_train.images_ids_in_subset),2048))\n",
    "Y_train = np.zeros((len(data_generator_train.images_ids_in_subset),20))\n",
    "\n",
    "# Calcul du nombre e batchs\n",
    "nb_batches = int(len(data_generator_train.images_ids_in_subset) / batch_size) + 1\n",
    "\n",
    "for i in range(nb_batches):\n",
    "    # Pour chaque batch, on extrait les images d'entrée X et les labels y\n",
    "    X, y = next(generator)\n",
    "    # On récupère les Deep Feature par appel à predict\n",
    "    y_pred = model.predict(X)\n",
    "    X_train[i*batch_size:(i+1)*batch_size,:] = y_pred\n",
    "    Y_train[i*batch_size:(i+1)*batch_size,:] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for test\n",
    "data_generator_test = PascalVOCDataGenerator('test', data_dir)\n",
    "generator_test = data_generator_test.flow(batch_size=batch_size)\n",
    "\n",
    "X_test = np.zeros((len(data_generator_test.images_ids_in_subset),2048))\n",
    "Y_test = np.zeros((len(data_generator_test.images_ids_in_subset),20))\n",
    "\n",
    "nb_batches = int(len(data_generator_test.images_ids_in_subset) / batch_size) + 1\n",
    "\n",
    "for i in range(nb_batches):\n",
    "    X, y = next(generator_test)\n",
    "    y_pred = model.predict(X)\n",
    "    X_test[i*batch_size:(i+1)*batch_size,:] = y_pred\n",
    "    Y_test[i*batch_size:(i+1)*batch_size,:] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'DF_ResNet50_VOC2007_test28'\n",
    "np.savez(outfile, X_train=X_train, Y_train=Y_train,X_test=X_test, Y_test=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifier only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'DF_ResNet50_VOC2007_test28.npz'\n",
    "learning_rate = 0.1\n",
    "nb_epoch = 20\n",
    "batch_size = 32\n",
    "\n",
    "npzfile = np.load(outfile)\n",
    "\n",
    "X_train = npzfile['X_train']\n",
    "Y_train = npzfile['Y_train']\n",
    "\n",
    "X_test = npzfile['X_test']\n",
    "Y_test = npzfile['Y_test']\n",
    "\n",
    "print(\"data \\n X_train=\", X_train.shape, \"Y_train=\", Y_train.shape, \" X_test=\", X_test.shape, \"Y_train=\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=2048, name='fc1', activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "sgd = SGD(learning_rate)\n",
    "model.compile(loss='binary_crossentropy',optimizer=sgd,metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,batch_size=batch_size, epochs=nb_epoch,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"%s TEST: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
    "print(\"%s TEST: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_train = model.predict(X_train)\n",
    "AP_train = np.zeros(20)\n",
    "AP_test = np.zeros(20)\n",
    "\n",
    "for c in range(20):\n",
    "    AP_train[c] = average_precision_score(Y_train[:, c], y_pred_train[:, c])\n",
    "    AP_test[c] = average_precision_score(Y_test[:, c], y_pred_test[:, c])\n",
    "\n",
    "print(\"MAP TRAIN =%.2f\", AP_train.mean()*100)\n",
    "print(\"MAP TEST =%.2f\", AP_test.mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_test = PascalVOCDataGenerator('test', data_dir)\n",
    "len(data_generator_test.images_ids_in_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(data_generator_test.images_ids_in_subset)\n",
    "generator_test = data_generator_test.flow(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = next(generator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(model, X_test, Y_test):\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    #y_pred_train = model.predict(X_train)\n",
    "\n",
    "    #AP_train = np.zeros(20)\n",
    "    AP_test = np.zeros(20)\n",
    "    for c in range(20):\n",
    "        #AP_train[c] = average_precision_score(Y_train[:, c], y_pred_train[:, c])\n",
    "        AP_test[c] = metrics.average_precision_score(Y_test[:, c], y_pred_test[:, c])\n",
    "\n",
    "    #print \"MAP TRAIN =\", AP_train.mean()*100\n",
    "    print(\"MAP TEST =\", AP_test.mean()*100)\n",
    "    print(AP_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_fn(model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(AP_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/'\n",
    "data_generator_train = PascalVOCDataGenerator('trainval', data_dir, prop=prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vanilla from RCP209\n",
    "model = ResNet50(include_top=True, weights='imagenet')\n",
    "model.layers.pop()\n",
    "# Modify top layers\n",
    "x = model.layers[-1].output\n",
    "x = Dense(data_generator_train.nb_classes, activation='sigmoid', name='predictions')(x)\n",
    "model = Model(inputs=model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the Dense(1000)\n",
    "model = ResNet50(include_top=True, weights='imagenet')\n",
    "x = model.layers[-2].output\n",
    "x = Dense(data_generator_train.nb_classes, activation='sigmoid', name='predictions')(x)\n",
    "model = Model(inputs=model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laura way\n",
    "# Load ResNet50 architecture & its weights\n",
    "input_shape = (224, 224, 3)\n",
    "resnet = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "inp = Input(shape=input_shape, name='image_input')\n",
    "x = resnet(inp)\n",
    "x = Flatten()(x)\n",
    "output = Dense(data_generator_train.nb_classes, activation='sigmoid')(x)\n",
    "model = Model(inputs=inp, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "# model.compile(loss='binary_crossentropy', optimizer=SGD(lr=lr), metrics=['binary_accuracy'])\n",
    "loss = BCE()\n",
    "# loss = PartialBCE(prop / 100)\n",
    "model.compile(loss=loss, optimizer=SGD(lr=0.01), metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "data_generator_test = PascalVOCDataGenerator('test', data_dir)\n",
    "len(data_generator_test.images_ids_in_subset)\n",
    "batch_size = len(data_generator_test.images_ids_in_subset)\n",
    "generator_test = data_generator_test.flow(batch_size=batch_size)\n",
    "X_test, Y_test = next(generator_test)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "exp_folder = '/home/caleml/partial_experiments/exp_20190724_1659_TESTNB'\n",
    "os.makedirs(exp_folder, exist_ok=True)\n",
    "\n",
    "cb_list = list()\n",
    "cb_list.append(SaveModel(exp_folder, prop))\n",
    "\n",
    "data_generator_test = PascalVOCDataGenerator('test', data_dir)\n",
    "map_cb = MAPCallback(X_test, Y_test, exp_folder, prop)\n",
    "cb_list.append(map_cb)\n",
    "\n",
    "# cb_list.append(LearningRateScheduler(lr_scheduler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "nb_epochs=25\n",
    "\n",
    "steps_per_epoch_train = int(len(data_generator_train.id_to_label) / batch_size) + 1\n",
    "model.fit_generator(data_generator_train.flow(batch_size=batch_size),\n",
    "                    steps_per_epoch=steps_per_epoch_train,\n",
    "                    epochs=nb_epochs,\n",
    "                    callbacks=cb_list,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/'\n",
    "data_generator_train = PascalVOCDataGenerator('trainval', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nico_data = data_generator_train.id_to_label\n",
    "print(len(nico_data))\n",
    "print(nico_data['000131'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_path = '/share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/Annotations/annotations_multilabel_trainval.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laura_data = dict()\n",
    "with open(trainval_path, 'r') as f_in:\n",
    "    for line in f_in:\n",
    "        parts = line.strip().split(',')\n",
    "        laura_data[parts[0]] = [int(elt) for elt in parts[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(laura_data))\n",
    "print(laura_data['000131'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_img, labels in nico_data.items():\n",
    "    laura_labels = laura_data[id_img]\n",
    "    converted = [l if l in [0, 1] else 0 for l in laura_labels]\n",
    "    assert all([converted[i] == labels[i] for i in range(len(labels))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

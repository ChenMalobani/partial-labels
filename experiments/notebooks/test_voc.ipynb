{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from experiments.data_gen import PascalVOCDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.callbacks.metric_callbacks import MAPCallback\n",
    "from model.callbacks.save_callback import SaveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.losses import BCE, PartialBCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop=60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From http://cedric.cnam.fr/vertigo/Cours/ml2/tpDeepLearning5.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 architecture & its weights\n",
    "# imagenet_model = ResNet50(include_top=True, weights='imagenet')\n",
    "# model.layers.pop()\n",
    "# Modify top layers\n",
    "# x = model.layers[-1].output\n",
    "# x = Dense(data_generator_train.nb_classes, activation='sigmoid', name='predictions')(x)\n",
    "# model = Model(inputs=model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagenet only model (no finetuning)\n",
    "model = ResNet50(include_top=True, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers.pop().pop()\n",
    "model = Model(inputs=model.input,outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(lr, momentum=0.9), metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/'\n",
    "data_generator_train = PascalVOCDataGenerator('trainval', data_dir, prop=prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_train = PascalVOCDataGenerator('trainval', data_dir, force_old=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "generator = data_generator_train.flow(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilisation des matrices contenant les Deep Features et les labels\n",
    "X_train = np.zeros((len(data_generator_train.images_ids_in_subset),2048))\n",
    "Y_train = np.zeros((len(data_generator_train.images_ids_in_subset),20))\n",
    "\n",
    "# Calcul du nombre e batchs\n",
    "nb_batches = int(len(data_generator_train.images_ids_in_subset) / batch_size) + 1\n",
    "\n",
    "for i in range(nb_batches):\n",
    "    # Pour chaque batch, on extrait les images d'entrée X et les labels y\n",
    "    X, y = next(generator)\n",
    "    # On récupère les Deep Feature par appel à predict\n",
    "    y_pred = model.predict(X)\n",
    "    X_train[i*batch_size:(i+1)*batch_size,:] = y_pred\n",
    "    Y_train[i*batch_size:(i+1)*batch_size,:] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for test\n",
    "data_generator_test = PascalVOCDataGenerator('test', data_dir)\n",
    "generator_test = data_generator_test.flow(batch_size=batch_size)\n",
    "\n",
    "X_test = np.zeros((len(data_generator_test.images_ids_in_subset),2048))\n",
    "Y_test = np.zeros((len(data_generator_test.images_ids_in_subset),20))\n",
    "\n",
    "nb_batches = int(len(data_generator_test.images_ids_in_subset) / batch_size) + 1\n",
    "\n",
    "for i in range(nb_batches):\n",
    "    X, y = next(generator_test)\n",
    "    y_pred = model.predict(X)\n",
    "    X_test[i*batch_size:(i+1)*batch_size,:] = y_pred\n",
    "    Y_test[i*batch_size:(i+1)*batch_size,:] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'DF_ResNet50_VOC2007_test28'\n",
    "np.savez(outfile, X_train=X_train, Y_train=Y_train,X_test=X_test, Y_test=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifier only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'DF_ResNet50_VOC2007_test28.npz'\n",
    "learning_rate = 0.1\n",
    "nb_epoch = 20\n",
    "batch_size = 32\n",
    "\n",
    "npzfile = np.load(outfile)\n",
    "\n",
    "X_train = npzfile['X_train']\n",
    "Y_train = npzfile['Y_train']\n",
    "\n",
    "X_test = npzfile['X_test']\n",
    "Y_test = npzfile['Y_test']\n",
    "\n",
    "print(\"data \\n X_train=\", X_train.shape, \"Y_train=\", Y_train.shape, \" X_test=\", X_test.shape, \"Y_train=\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=2048, name='fc1', activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "sgd = SGD(learning_rate)\n",
    "model.compile(loss='binary_crossentropy',optimizer=sgd,metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,batch_size=batch_size, epochs=nb_epoch,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"%s TEST: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
    "print(\"%s TEST: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_train = model.predict(X_train)\n",
    "AP_train = np.zeros(20)\n",
    "AP_test = np.zeros(20)\n",
    "\n",
    "for c in range(20):\n",
    "    AP_train[c] = average_precision_score(Y_train[:, c], y_pred_train[:, c])\n",
    "    AP_test[c] = average_precision_score(Y_test[:, c], y_pred_test[:, c])\n",
    "\n",
    "print(\"MAP TRAIN =%.2f\", AP_train.mean()*100)\n",
    "print(\"MAP TEST =%.2f\", AP_test.mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_test = PascalVOCDataGenerator('test', data_dir)\n",
    "len(data_generator_test.images_ids_in_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(data_generator_test.images_ids_in_subset)\n",
    "generator_test = data_generator_test.flow(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = next(generator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(model, X_test, Y_test):\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    #y_pred_train = model.predict(X_train)\n",
    "\n",
    "    #AP_train = np.zeros(20)\n",
    "    AP_test = np.zeros(20)\n",
    "    for c in range(20):\n",
    "        #AP_train[c] = average_precision_score(Y_train[:, c], y_pred_train[:, c])\n",
    "        AP_test[c] = metrics.average_precision_score(Y_test[:, c], y_pred_test[:, c])\n",
    "\n",
    "    #print \"MAP TRAIN =\", AP_train.mean()*100\n",
    "    print(\"MAP TEST =\", AP_test.mean()*100)\n",
    "    print(AP_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_fn(model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(AP_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset from /share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/Annotations/annotations_multilabel_trainval_partial_60_1.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/'\n",
    "data_generator_train = PascalVOCDataGenerator('trainval', data_dir, prop=prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vanilla from RCP209\n",
    "model = ResNet50(include_top=True, weights='imagenet')\n",
    "model.layers.pop()\n",
    "# Modify top layers\n",
    "x = model.layers[-1].output\n",
    "x = Dense(data_generator_train.nb_classes, activation='sigmoid', name='predictions')(x)\n",
    "model = Model(inputs=model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the Dense(1000)\n",
    "model = ResNet50(include_top=True, weights='imagenet')\n",
    "x = model.layers[-2].output\n",
    "x = Dense(data_generator_train.nb_classes, activation='sigmoid', name='predictions')(x)\n",
    "model = Model(inputs=model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laura way\n",
    "# Load ResNet50 architecture & its weights\n",
    "input_shape = (224, 224, 3)\n",
    "resnet = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "inp = Input(shape=input_shape, name='image_input')\n",
    "x = resnet(inp)\n",
    "x = Flatten()(x)\n",
    "output = Dense(data_generator_train.nb_classes, activation='sigmoid')(x)\n",
    "model = Model(inputs=inp, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "# model.compile(loss='binary_crossentropy', optimizer=SGD(lr=lr), metrics=['binary_accuracy'])\n",
    "# loss = BCE()\n",
    "loss = PartialBCE(prop / 100)\n",
    "model.compile(loss=loss, optimizer=SGD(lr=lr), metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset from /share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/Annotations/annotations_multilabel_test.csv\n",
      "(4952, 224, 224, 3) (4952, 20)\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "data_generator_test = PascalVOCDataGenerator('test', data_dir)\n",
    "len(data_generator_test.images_ids_in_subset)\n",
    "batch_size = len(data_generator_test.images_ids_in_subset)\n",
    "generator_test = data_generator_test.flow(batch_size=batch_size)\n",
    "X_test, Y_test = next(generator_test)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "exp_folder = '/home/caleml/partial_experiments/exp_20190722_1416_TESTNB'\n",
    "os.makedirs(exp_folder, exist_ok=True)\n",
    "\n",
    "cb_list = list()\n",
    "cb_list.append(SaveModel(exp_folder, prop))\n",
    "\n",
    "map_cb = MAPCallback(X_test, Y_test, exp_folder, prop)\n",
    "cb_list.append(map_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.3343 - binary_accuracy: 0.4050\n",
      "Trying to save model @epoch=001 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_001.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_001.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 0 - mAP score: 0.787593\n",
      "157/157 [==============================] - 266s 2s/step - loss: 0.3344 - binary_accuracy: 0.4050\n",
      "Epoch 2/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1226 - binary_accuracy: 0.4150\n",
      "Trying to save model @epoch=002 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_002.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_002.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 1 - mAP score: 0.816291\n",
      "157/157 [==============================] - 71s 450ms/step - loss: 0.1228 - binary_accuracy: 0.4149\n",
      "Epoch 3/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0546 - binary_accuracy: 0.4197\n",
      "Trying to save model @epoch=003 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_003.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_003.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 2 - mAP score: 0.819526\n",
      "157/157 [==============================] - 71s 450ms/step - loss: 0.0546 - binary_accuracy: 0.4197\n",
      "Epoch 4/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0241 - binary_accuracy: 0.4217\n",
      "Trying to save model @epoch=004 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_004.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_004.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 3 - mAP score: 0.832526\n",
      "157/157 [==============================] - 71s 449ms/step - loss: 0.0241 - binary_accuracy: 0.4217\n",
      "Epoch 5/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0138 - binary_accuracy: 0.4223\n",
      "Trying to save model @epoch=005 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_005.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_005.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 4 - mAP score: 0.835171\n",
      "157/157 [==============================] - 71s 449ms/step - loss: 0.0139 - binary_accuracy: 0.4222\n",
      "Epoch 6/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0090 - binary_accuracy: 0.4227\n",
      "Trying to save model @epoch=006 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_006.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_006.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 5 - mAP score: 0.830391\n",
      "157/157 [==============================] - 71s 453ms/step - loss: 0.0090 - binary_accuracy: 0.4228\n",
      "Epoch 7/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0063 - binary_accuracy: 0.4228\n",
      "Trying to save model @epoch=007 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_007.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_007.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 6 - mAP score: 0.835986\n",
      "157/157 [==============================] - 69s 442ms/step - loss: 0.0065 - binary_accuracy: 0.4230\n",
      "Epoch 8/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0053 - binary_accuracy: 0.4226\n",
      "Trying to save model @epoch=008 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_008.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_008.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 7 - mAP score: 0.834596\n",
      "157/157 [==============================] - 68s 435ms/step - loss: 0.0053 - binary_accuracy: 0.4227\n",
      "Epoch 9/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0048 - binary_accuracy: 0.4229\n",
      "Trying to save model @epoch=009 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_009.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_009.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 8 - mAP score: 0.832855\n",
      "157/157 [==============================] - 68s 436ms/step - loss: 0.0049 - binary_accuracy: 0.4228\n",
      "Epoch 10/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0038 - binary_accuracy: 0.4227\n",
      "Trying to save model @epoch=010 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_010.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_010.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 9 - mAP score: 0.834789\n",
      "157/157 [==============================] - 80s 507ms/step - loss: 0.0038 - binary_accuracy: 0.4228\n",
      "Epoch 11/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0030 - binary_accuracy: 0.4227\n",
      "Trying to save model @epoch=011 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_011.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_011.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 10 - mAP score: 0.836414\n",
      "157/157 [==============================] - 89s 566ms/step - loss: 0.0030 - binary_accuracy: 0.4228\n",
      "Epoch 12/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0024 - binary_accuracy: 0.4230\n",
      "Trying to save model @epoch=012 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_012.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_012.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 11 - mAP score: 0.833689\n",
      "157/157 [==============================] - 92s 587ms/step - loss: 0.0024 - binary_accuracy: 0.4230\n",
      "Epoch 13/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0026 - binary_accuracy: 0.4226\n",
      "Trying to save model @epoch=013 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_013.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_013.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 12 - mAP score: 0.836731\n",
      "157/157 [==============================] - 118s 749ms/step - loss: 0.0026 - binary_accuracy: 0.4227\n",
      "Epoch 14/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0020 - binary_accuracy: 0.4229\n",
      "Trying to save model @epoch=014 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_014.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_014.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 13 - mAP score: 0.836229\n",
      "157/157 [==============================] - 130s 825ms/step - loss: 0.0021 - binary_accuracy: 0.4230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0018 - binary_accuracy: 0.4226\n",
      "Trying to save model @epoch=015 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_015.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_015.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 14 - mAP score: 0.837410\n",
      "157/157 [==============================] - 135s 861ms/step - loss: 0.0019 - binary_accuracy: 0.4226\n",
      "Epoch 16/25\n",
      "156/157 [============================>.] - ETA: 1s - loss: 0.0015 - binary_accuracy: 0.4227\n",
      "Trying to save model @epoch=016 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_016.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_016.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 15 - mAP score: 0.837588\n",
      "157/157 [==============================] - 177s 1s/step - loss: 0.0015 - binary_accuracy: 0.4227\n",
      "Epoch 17/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0014 - binary_accuracy: 0.4228\n",
      "Trying to save model @epoch=017 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_017.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_017.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 16 - mAP score: 0.837652\n",
      "157/157 [==============================] - 160s 1s/step - loss: 0.0014 - binary_accuracy: 0.4228\n",
      "Epoch 18/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0012 - binary_accuracy: 0.4229\n",
      "Trying to save model @epoch=018 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_018.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_018.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 17 - mAP score: 0.837366\n",
      "157/157 [==============================] - 157s 1s/step - loss: 0.0013 - binary_accuracy: 0.4231\n",
      "Epoch 19/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0012 - binary_accuracy: 0.4229\n",
      "Trying to save model @epoch=019 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_019.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_019.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 18 - mAP score: 0.837435\n",
      "157/157 [==============================] - 152s 968ms/step - loss: 0.0012 - binary_accuracy: 0.4230\n",
      "Epoch 20/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0013 - binary_accuracy: 0.4228\n",
      "Trying to save model @epoch=020 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_020.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_020.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 19 - mAP score: 0.838447\n",
      "157/157 [==============================] - 121s 772ms/step - loss: 0.0013 - binary_accuracy: 0.4228\n",
      "Epoch 21/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0011 - binary_accuracy: 0.4228\n",
      "Trying to save model @epoch=021 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_021.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_021.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 20 - mAP score: 0.838074\n",
      "157/157 [==============================] - 115s 734ms/step - loss: 0.0011 - binary_accuracy: 0.4229\n",
      "Epoch 22/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0010 - binary_accuracy: 0.4229\n",
      "Trying to save model @epoch=022 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_022.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_022.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 21 - mAP score: 0.838604\n",
      "157/157 [==============================] - 108s 685ms/step - loss: 0.0010 - binary_accuracy: 0.4228\n",
      "Epoch 23/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 8.0692e-04 - binary_accuracy: 0.4230\n",
      "Trying to save model @epoch=023 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_023.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_023.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 22 - mAP score: 0.838452\n",
      "157/157 [==============================] - 95s 602ms/step - loss: 8.1439e-04 - binary_accuracy: 0.4229\n",
      "Epoch 24/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 8.7124e-04 - binary_accuracy: 0.4227\n",
      "Trying to save model @epoch=024 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_024.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_024.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 23 - mAP score: 0.837537\n",
      "157/157 [==============================] - 96s 612ms/step - loss: 8.7042e-04 - binary_accuracy: 0.4228\n",
      "Epoch 25/25\n",
      "156/157 [============================>.] - ETA: 0s - loss: 7.5021e-04 - binary_accuracy: 0.4230\n",
      "Trying to save model @epoch=025 to /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/model_60_025.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190722_1416_TESTNB/weights_60_025.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 24 - mAP score: 0.837684\n",
      "157/157 [==============================] - 96s 612ms/step - loss: 8.0202e-04 - binary_accuracy: 0.4232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5cc37b1c88>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=32\n",
    "nb_epochs=25\n",
    "\n",
    "steps_per_epoch_train = int(len(data_generator_train.id_to_label) / batch_size) + 1\n",
    "model.fit_generator(data_generator_train.flow(batch_size=batch_size),\n",
    "                    steps_per_epoch=steps_per_epoch_train,\n",
    "                    epochs=nb_epochs,\n",
    "                    callbacks=cb_list,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/'\n",
    "data_generator_train = PascalVOCDataGenerator('trainval', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nico_data = data_generator_train.id_to_label\n",
    "print(len(nico_data))\n",
    "print(nico_data['000131'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_path = '/share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/Annotations/annotations_multilabel_trainval.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laura_data = dict()\n",
    "with open(trainval_path, 'r') as f_in:\n",
    "    for line in f_in:\n",
    "        parts = line.strip().split(',')\n",
    "        laura_data[parts[0]] = [int(elt) for elt in parts[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(laura_data))\n",
    "print(laura_data['000131'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_img, labels in nico_data.items():\n",
    "    laura_labels = laura_data[id_img]\n",
    "    converted = [l if l in [0, 1] else 0 for l in laura_labels]\n",
    "    assert all([converted[i] == labels[i] for i in range(len(labels))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch.py surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

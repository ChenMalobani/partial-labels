{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Concatenate\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.pascalvoc.pascalvoc import PascalVOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.networks.baseline import Baseline\n",
    "from model.networks.prior import PriorModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.callbacks.metric_callbacks import MAPCallback\n",
    "from model.callbacks.save_callback import SaveModel\n",
    "from model.callbacks.scheduler import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.losses import BCE, PartialBCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.config import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_options_file('/home/caleml/partial-labels/config/pv_baseline50_sgd_448lrs.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From http://cedric.cnam.fr/vertigo/Cours/ml2/tpDeepLearning5.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 architecture & its weights\n",
    "# imagenet_model = ResNet50(include_top=True, weights='imagenet')\n",
    "# model.layers.pop()\n",
    "# Modify top layers\n",
    "# x = model.layers[-1].output\n",
    "# x = Dense(data_generator_train.nb_classes, activation='sigmoid', name='predictions')(x)\n",
    "# model = Model(inputs=model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagenet only model (no finetuning)\n",
    "model = ResNet50(include_top=True, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers.pop().pop()\n",
    "model = Model(inputs=model.input,outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(lr, momentum=0.9), metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/'\n",
    "data_generator_train = PascalVOCDataGenerator('trainval', data_dir, prop=prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_train = PascalVOCDataGenerator('trainval', data_dir, force_old=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "generator = data_generator_train.flow(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilisation des matrices contenant les Deep Features et les labels\n",
    "X_train = np.zeros((len(data_generator_train.images_ids_in_subset),2048))\n",
    "Y_train = np.zeros((len(data_generator_train.images_ids_in_subset),20))\n",
    "\n",
    "# Calcul du nombre e batchs\n",
    "nb_batches = int(len(data_generator_train.images_ids_in_subset) / batch_size) + 1\n",
    "\n",
    "for i in range(nb_batches):\n",
    "    # Pour chaque batch, on extrait les images d'entrée X et les labels y\n",
    "    X, y = next(generator)\n",
    "    # On récupère les Deep Feature par appel à predict\n",
    "    y_pred = model.predict(X)\n",
    "    X_train[i*batch_size:(i+1)*batch_size,:] = y_pred\n",
    "    Y_train[i*batch_size:(i+1)*batch_size,:] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for test\n",
    "data_generator_test = PascalVOCDataGenerator('test', data_dir)\n",
    "generator_test = data_generator_test.flow(batch_size=batch_size)\n",
    "\n",
    "X_test = np.zeros((len(data_generator_test.images_ids_in_subset),2048))\n",
    "Y_test = np.zeros((len(data_generator_test.images_ids_in_subset),20))\n",
    "\n",
    "nb_batches = int(len(data_generator_test.images_ids_in_subset) / batch_size) + 1\n",
    "\n",
    "for i in range(nb_batches):\n",
    "    X, y = next(generator_test)\n",
    "    y_pred = model.predict(X)\n",
    "    X_test[i*batch_size:(i+1)*batch_size,:] = y_pred\n",
    "    Y_test[i*batch_size:(i+1)*batch_size,:] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'DF_ResNet50_VOC2007_test28'\n",
    "np.savez(outfile, X_train=X_train, Y_train=Y_train,X_test=X_test, Y_test=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifier only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'DF_ResNet50_VOC2007_test28.npz'\n",
    "learning_rate = 0.1\n",
    "nb_epoch = 20\n",
    "batch_size = 32\n",
    "\n",
    "npzfile = np.load(outfile)\n",
    "\n",
    "X_train = npzfile['X_train']\n",
    "Y_train = npzfile['Y_train']\n",
    "\n",
    "X_test = npzfile['X_test']\n",
    "Y_test = npzfile['Y_test']\n",
    "\n",
    "print(\"data \\n X_train=\", X_train.shape, \"Y_train=\", Y_train.shape, \" X_test=\", X_test.shape, \"Y_train=\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=2048, name='fc1', activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "sgd = SGD(learning_rate)\n",
    "model.compile(loss='binary_crossentropy',optimizer=sgd,metrics=['binary_accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,batch_size=batch_size, epochs=nb_epoch,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"%s TEST: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
    "print(\"%s TEST: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_train = model.predict(X_train)\n",
    "AP_train = np.zeros(20)\n",
    "AP_test = np.zeros(20)\n",
    "\n",
    "for c in range(20):\n",
    "    AP_train[c] = average_precision_score(Y_train[:, c], y_pred_train[:, c])\n",
    "    AP_test[c] = average_precision_score(Y_test[:, c], y_pred_test[:, c])\n",
    "\n",
    "print(\"MAP TRAIN =%.2f\", AP_train.mean()*100)\n",
    "print(\"MAP TEST =%.2f\", AP_test.mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_test = PascalVOCDataGenerator('test', data_dir)\n",
    "len(data_generator_test.images_ids_in_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(data_generator_test.images_ids_in_subset)\n",
    "generator_test = data_generator_test.flow(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = next(generator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(model, X_test, Y_test):\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    #y_pred_train = model.predict(X_train)\n",
    "\n",
    "    #AP_train = np.zeros(20)\n",
    "    AP_test = np.zeros(20)\n",
    "    for c in range(20):\n",
    "        #AP_train[c] = average_precision_score(Y_train[:, c], y_pred_train[:, c])\n",
    "        AP_test[c] = metrics.average_precision_score(Y_test[:, c], y_pred_test[:, c])\n",
    "\n",
    "    #print \"MAP TRAIN =\", AP_train.mean()*100\n",
    "    print(\"MAP TEST =\", AP_test.mean()*100)\n",
    "    print(AP_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_fn(model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(AP_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/'\n",
    "data_generator_train = PascalVOCDataGenerator('trainval', data_dir, prop=prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vanilla from RCP209\n",
    "model = ResNet50(include_top=True, weights='imagenet')\n",
    "model.layers.pop()\n",
    "# Modify top layers\n",
    "x = model.layers[-1].output\n",
    "x = Dense(data_generator_train.nb_classes, activation='sigmoid', name='predictions')(x)\n",
    "model = Model(inputs=model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the Dense(1000)\n",
    "model = ResNet50(include_top=True, weights='imagenet')\n",
    "x = model.layers[-2].output\n",
    "x = Dense(data_generator_train.nb_classes, activation='sigmoid', name='predictions')(x)\n",
    "model = Model(inputs=model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laura way\n",
    "# Load ResNet50 architecture & its weights\n",
    "input_shape = (224, 224, 3)\n",
    "resnet = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "inp = Input(shape=input_shape, name='image_input')\n",
    "x = resnet(inp)\n",
    "x = Flatten()(x)\n",
    "output = Dense(data_generator_train.nb_classes, activation='sigmoid')(x)\n",
    "model = Model(inputs=inp, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "# model.compile(loss='binary_crossentropy', optimizer=SGD(lr=lr), metrics=['binary_accuracy'])\n",
    "loss = BCE()\n",
    "# loss = PartialBCE(prop / 100)\n",
    "model.compile(loss=loss, optimizer=SGD(lr=0.01), metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "data_generator_test = PascalVOCDataGenerator('test', data_dir)\n",
    "len(data_generator_test.images_ids_in_subset)\n",
    "batch_size = len(data_generator_test.images_ids_in_subset)\n",
    "generator_test = data_generator_test.flow(batch_size=batch_size)\n",
    "X_test, Y_test = next(generator_test)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "exp_folder = '/home/caleml/partial_experiments/exp_20190724_1659_TESTNB'\n",
    "os.makedirs(exp_folder, exist_ok=True)\n",
    "\n",
    "cb_list = list()\n",
    "cb_list.append(SaveModel(exp_folder, prop))\n",
    "\n",
    "data_generator_test = PascalVOCDataGenerator('test', data_dir)\n",
    "map_cb = MAPCallback(X_test, Y_test, exp_folder, prop)\n",
    "cb_list.append(map_cb)\n",
    "\n",
    "# cb_list.append(LearningRateScheduler(lr_scheduler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "nb_epochs=25\n",
    "\n",
    "steps_per_epoch_train = int(len(data_generator_train.id_to_label) / batch_size) + 1\n",
    "model.fit_generator(data_generator_train.flow(batch_size=batch_size),\n",
    "                    steps_per_epoch=steps_per_epoch_train,\n",
    "                    epochs=nb_epochs,\n",
    "                    callbacks=cb_list,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/'\n",
    "data_generator_train = PascalVOCDataGenerator('trainval', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nico_data = data_generator_train.id_to_label\n",
    "print(len(nico_data))\n",
    "print(nico_data['000131'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_path = '/share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/Annotations/annotations_multilabel_trainval.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laura_data = dict()\n",
    "with open(trainval_path, 'r') as f_in:\n",
    "    for line in f_in:\n",
    "        parts = line.strip().split(',')\n",
    "        laura_data[parts[0]] = [int(elt) for elt in parts[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(laura_data))\n",
    "print(laura_data['000131'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_img, labels in nico_data.items():\n",
    "    laura_labels = laura_data[id_img]\n",
    "    converted = [l if l in [0, 1] else 0 for l in laura_labels]\n",
    "    assert all([converted[i] == labels[i] for i in range(len(labels))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.networks.prior import PriorModel\n",
    "from model.callbacks.prior_callback import PriorCallback\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_folder = '/home/caleml/partial_experiments/exp_20190812_1654_TESTNB'\n",
    "os.makedirs(exp_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "data_dir = '/share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/'\n",
    "dataset_train = PascalVOCDataGenerator('trainval', data_dir, prop=prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PriorModel(exp_folder, dataset_train.nb_classes, prop)\n",
    "model.load_config('pv_prior50_sgd')\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "prior_cb = PriorCallback()\n",
    "fetches = [tf.assign(prior_cb.var_y_true, model.targets[0], validate_shape=False),\n",
    "           tf.assign(prior_cb.var_y_pred, model.outputs[0], validate_shape=False)]\n",
    "model._function_kwargs = {'fetches': fetches}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "steps_per_epoch = int(len(dataset_train.id_to_label) / cfg.BATCH_SIZE) + 1\n",
    "model.train(dataset_train.flow(batch_size=cfg.BATCH_SIZE), steps_per_epoch=steps_per_epoch, cb_list=cb_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/caleml/datasets/pascalvoc/VOCdevkit/VOC2007/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dataset = PascalVOCDataGenerator('trainval', data_dir, prop=prop)\n",
    "new_dataset = PascalVOC(data_dir, 16, 'trainval', x_keys=['image'], y_keys=['multilabel'], p=prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison function\n",
    "def compare(d_old, d_new):\n",
    "    \n",
    "    batch1 = next(d_old)\n",
    "    batch2 = d_new[0]\n",
    "    print(type(batch1), type(batch2))\n",
    "    print(len(batch1), len(batch2))\n",
    "    x1, y1 = batch1\n",
    "    x2, y2 = batch2\n",
    "    print(type(x1), type(x2))\n",
    "    print(type(y1), type(y2))\n",
    "    print(x1.shape, np.array(x2).shape, len(x2))\n",
    "    print(y1.shape, np.array(y2).shape, len(y2))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    a = fig.add_subplot(1,3,1)\n",
    "    imgplot = plt.imshow(x1[0])\n",
    "    a = fig.add_subplot(1,3,2)\n",
    "    imgplot = plt.imshow(x2[0][0])\n",
    "    a = fig.add_subplot(1,3,3)\n",
    "    first_img = '/share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/JPEGImages/000005.jpg'\n",
    "    img = mpimg.imread(first_img)\n",
    "    imgplot = plt.imshow(img)\n",
    "    \n",
    "    assert np.array_equal(x1, np.array(x2[0]))\n",
    "    assert np.array_equal(y1, np.array(y2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(old_dataset.flow(batch_size=16), new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 3, 4, 7, 8, 9]\n",
    "a[[1,2,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(6)\n",
    "a[1] = 6\n",
    "a[2] = 7\n",
    "a[-1] = 12\n",
    "a[0] = 3\n",
    "\n",
    "b = a / sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b, sum(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New finetune with prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/caleml/datasets/pascalvoc/VOCdevkit/VOC2007/'\n",
    "dataset_train = PascalVOC(data_dir, 16, 'trainval', x_keys=['image'], y_keys=['multilabel'], p=prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_folder = '/home/caleml/partial_experiments/exp_20190829_1434_TESTNB'\n",
    "os.makedirs(exp_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.networks.prior import PriorModel\n",
    "model = PriorModel(exp_folder, dataset_train.nb_classes, prop)\n",
    "model.load_config('pv_baseline50_sgd')\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dataset_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = PascalVOC(data_dir, 4952, 'test', x_keys=['image'], y_keys=['multilabel'])\n",
    "X_test, Y_test = dataset_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "cb_list = list()\n",
    "\n",
    "map_cb = MAPCallback(X_test, Y_test, exp_folder, prop)\n",
    "cb_list.append(map_cb)\n",
    "\n",
    "cb_list.append(SaveModel(exp_folder, prop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual train\n",
    "steps_per_epoch = len(dataset_train)\n",
    "model.train(dataset_train, steps_per_epoch=steps_per_epoch, cb_list=cb_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(9).reshape(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.repeat(x[None,...],10,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kullback_leibler_div(p, q):\n",
    "    p = K.clip(p, K.epsilon(), 1)\n",
    "    q = K.clip(q, K.epsilon(), 1)\n",
    "    return K.sum(p * K.log(p / q), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kullback_leibler_div2(c):\n",
    "    p = c[0]\n",
    "    q = c[1]\n",
    "    p = K.clip(p, K.epsilon(), 1)\n",
    "    q = K.clip(q, K.epsilon(), 1)\n",
    "    return K.sum(p * K.log(p / q), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kvar = K.variable(np.array([[1, 2], [3, 4]]), dtype='float32')\n",
    "K.eval(kvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_cooc = np.array([[0.06060606, 0.03030303, 0.75757576],\n",
    " [0.00456621, 0.00913242, 0.03652968],\n",
    " [0.11764706, 0.02941176, 0.05882353]])\n",
    "np_logits = np.array([0.7, 0.15, 0.15])\n",
    "\n",
    "fake_cooc = K.variable(np_cooc, dtype='float32')\n",
    "fake_logits = K.variable(np_logits, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.eval([kullback_leibler_div(fake_cooc[i], fake_logits) for i in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_logits = tf.tile(tf.expand_dims(fake_logits, 0), [3, 1])\n",
    "broad_logits.shape\n",
    "# out = tf.map_fn(kullback_leibler_div2, (fake_cooc, broad_logits), dtype=(tf.float32, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.eval(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.eval(tf.concat([fake_cooc, broad_logits], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.eval(tf.tile(tf.expand_dims(fake_logits, 0), [3, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.eval(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = tf.keras.layers.Input(shape=(3,3))\n",
    "logits = tf.keras.layers.Input(shape=(3,))\n",
    "print(logits.shape)\n",
    "print(matrix.shape)\n",
    "\n",
    "# broad_logits = tf.tile(tf.expand_dims(logits, 0), [3, 1])\n",
    "broad_logits = tf.tile(logits, [3, 1])\n",
    "print(broad_logits.shape)\n",
    "out = tf.map_fn(kullback_leibler_div2, (matrix, broad_logits), dtype=(tf.float32, tf.float32))\n",
    "\n",
    "test_model = tensorflow.keras.models.Model(inputs=[input1, input2], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

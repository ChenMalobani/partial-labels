{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from experiments.data_gen import PascalVOCDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.callbacks.metric_callbacks import MAPCallback\n",
    "from model.callbacks.save_callback import SaveModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.losses import BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop=70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(include_top=True, weights='imagenet')\n",
    "model.layers.pop()\n",
    "model = Model(input=model.input, output=model.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(lr, momentum=0.9), metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset from /share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/Annotations/annotations_multilabel_trainval_partial_70_1.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/'\n",
    "data_generator_train = PascalVOCDataGenerator('trainval', data_dir, prop=prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "generator = data_generator_train.flow(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initilisation des matrices contenant les Deep Features et les labels\n",
    "X_train = np.zeros((len(data_generator_train.images_ids_in_subset),2048))\n",
    "Y_train = np.zeros((len(data_generator_train.images_ids_in_subset),20))\n",
    "\n",
    "# Calcul du nombre e batchs\n",
    "nb_batches = int(len(data_generator_train.images_ids_in_subset) / batch_size) + 1\n",
    "\n",
    "for i in range(nb_batches):\n",
    "    # Pour chaque batch, on extrait les images d'entrée X et les labels y\n",
    "    X, y = next(generator)\n",
    "    # On récupère les Deep Feature par appel à predict\n",
    "    y_pred = model.predict(X)\n",
    "    X_train[i*batch_size:(i+1)*batch_size,:] = y_pred\n",
    "    Y_train[i*batch_size:(i+1)*batch_size,:] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(20,  input_dim=2048, name='fc1', activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "sgd = SGD(learning_rate)\n",
    "model.compile(loss='binary_crossentropy',optimizer=sgd,metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train,batch_size=batch_size, epochs=nb_epoch,verbose=1)\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"%s TEST: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
    "print(\"%s TEST: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4952"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generator_test = PascalVOCDataGenerator('test', data_dir)\n",
    "len(data_generator_test.images_ids_in_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(data_generator_test.images_ids_in_subset)\n",
    "generator_test = data_generator_test.flow(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = next(generator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(model, X_test, Y_test):\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    #y_pred_train = model.predict(X_train)\n",
    "\n",
    "    #AP_train = np.zeros(20)\n",
    "    AP_test = np.zeros(20)\n",
    "    for c in range(20):\n",
    "        #AP_train[c] = average_precision_score(Y_train[:, c], y_pred_train[:, c])\n",
    "        AP_test[c] = metrics.average_precision_score(Y_test[:, c], y_pred_test[:, c])\n",
    "\n",
    "    #print \"MAP TRAIN =\", AP_train.mean()*100\n",
    "    print(\"MAP TEST =\", AP_test.mean()*100)\n",
    "    print(AP_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_fn(model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(AP_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vanilla from RCP209\n",
    "model = ResNet50(include_top=True, weights='imagenet')\n",
    "model.layers.pop()\n",
    "# Modify top layers\n",
    "x = model.layers[-1].output\n",
    "x = Dense(data_generator_train.nb_classes, activation='sigmoid', name='predictions')(x)\n",
    "model = Model(inputs=model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caleml/.local/lib/python3.4/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "# Laura way\n",
    "# Load ResNet50 architecture & its weights\n",
    "input_shape = (224, 224, 3)\n",
    "resnet = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "inp = Input(shape=input_shape, name='image_input')\n",
    "x = resnet(inp)\n",
    "x = Flatten()(x)\n",
    "output = Dense(data_generator_train.nb_classes, activation='sigmoid')(x)\n",
    "model = Model(inputs=inp, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                2007060   \n",
      "=================================================================\n",
      "Total params: 25,594,772\n",
      "Trainable params: 25,541,652\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "# model.compile(loss='binary_crossentropy', optimizer=SGD(lr=lr), metrics=['binary_accuracy'])\n",
    "loss = BCE()\n",
    "model.compile(loss=loss, optimizer=SGD(lr=lr), metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "exp_folder = '/home/caleml/partial_experiments/exp_20190628_0258_TESTNB'\n",
    "\n",
    "cb_list = list()\n",
    "cb_list.append(SaveModel(exp_folder, prop))\n",
    "\n",
    "map_cb = MAPCallback(X_test, Y_test, exp_folder)\n",
    "cb_list.append(map_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset from /share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/Annotations/annotations_multilabel_trainval_partial_70_1.csv\n",
      "Epoch 1/20\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.6438 - binary_accuracy: 0.3092\n",
      "Trying to save model @epoch=001 to /home/caleml/partial_experiments/exp_20190628_0258_TESTNB/model_70_001.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190628_0258_TESTNB/weights_70_001.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 0 - mAP score: 0.136883\n",
      "157/157 [==============================] - 87s 553ms/step - loss: 0.6415 - binary_accuracy: 0.3093\n",
      "Epoch 2/20\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.2289 - binary_accuracy: 0.3134\n",
      "Trying to save model @epoch=002 to /home/caleml/partial_experiments/exp_20190628_0258_TESTNB/model_70_002.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190628_0258_TESTNB/weights_70_002.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 1 - mAP score: 0.091936\n",
      "157/157 [==============================] - 73s 463ms/step - loss: 0.2299 - binary_accuracy: 0.3133\n",
      "Epoch 3/20\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.2347 - binary_accuracy: 0.3140\n",
      "Trying to save model @epoch=003 to /home/caleml/partial_experiments/exp_20190628_0258_TESTNB/model_70_003.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190628_0258_TESTNB/weights_70_003.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 2 - mAP score: 0.406751\n",
      "157/157 [==============================] - 74s 470ms/step - loss: 0.2344 - binary_accuracy: 0.3141\n",
      "Epoch 4/20\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.1976 - binary_accuracy: 0.3176\n",
      "Trying to save model @epoch=004 to /home/caleml/partial_experiments/exp_20190628_0258_TESTNB/model_70_004.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190628_0258_TESTNB/weights_70_004.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 3 - mAP score: 0.078859\n",
      "157/157 [==============================] - 74s 469ms/step - loss: 0.1980 - binary_accuracy: 0.3175\n",
      "Epoch 5/20\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.2692 - binary_accuracy: 0.3069\n",
      "Trying to save model @epoch=005 to /home/caleml/partial_experiments/exp_20190628_0258_TESTNB/model_70_005.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190628_0258_TESTNB/weights_70_005.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 4 - mAP score: 0.231214\n",
      "157/157 [==============================] - 74s 472ms/step - loss: 0.2698 - binary_accuracy: 0.3068\n",
      "Epoch 6/20\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.2209 - binary_accuracy: 0.3114\n",
      "Trying to save model @epoch=006 to /home/caleml/partial_experiments/exp_20190628_0258_TESTNB/model_70_006.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190628_0258_TESTNB/weights_70_006.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 5 - mAP score: 0.232153\n",
      "157/157 [==============================] - 74s 473ms/step - loss: 0.2212 - binary_accuracy: 0.3114\n",
      "Epoch 7/20\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.2026 - binary_accuracy: 0.3155\n",
      "Trying to save model @epoch=007 to /home/caleml/partial_experiments/exp_20190628_0258_TESTNB/model_70_007.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190628_0258_TESTNB/weights_70_007.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 6 - mAP score: 0.318827\n",
      "157/157 [==============================] - 75s 475ms/step - loss: 0.2024 - binary_accuracy: 0.3156\n",
      "Epoch 8/20\n",
      "156/157 [============================>.] - ETA: 0s - loss: 0.0716 - binary_accuracy: 0.3299\n",
      "Trying to save model @epoch=008 to /home/caleml/partial_experiments/exp_20190628_0258_TESTNB/model_70_008.h5\n",
      "Couldn't save model, saving weights instead at /home/caleml/partial_experiments/exp_20190628_0258_TESTNB/weights_70_008.h5\n",
      "type true <class 'numpy.ndarray'>, type pred <class 'numpy.ndarray'>\n",
      "ap scores type <class 'numpy.ndarray'>\n",
      "interval evaluation - epoch: 7 - mAP score: 0.348116\n",
      "157/157 [==============================] - 74s 471ms/step - loss: 0.0716 - binary_accuracy: 0.3299\n",
      "Epoch 9/20\n",
      "120/157 [=====================>........] - ETA: 14s - loss: 0.0204 - binary_accuracy: 0.3409"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "nb_epochs=20\n",
    "data_generator_train = PascalVOCDataGenerator('trainval', data_dir, prop=prop)\n",
    "steps_per_epoch_train = int(len(data_generator_train.id_to_label) / batch_size) + 1\n",
    "model.fit_generator(data_generator_train.flow(batch_size=batch_size),\n",
    "                    steps_per_epoch=steps_per_epoch_train,\n",
    "                    epochs=nb_epochs,\n",
    "                    callbacks=cb_list,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/'\n",
    "data_generator_train = PascalVOCDataGenerator('trainval', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nico_data = data_generator_train.id_to_label\n",
    "print(len(nico_data))\n",
    "print(nico_data['000131'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_path = '/share/DEEPLEARNING/datasets/pascalvoc/VOCdevkit/VOC2007/Annotations/annotations_multilabel_trainval.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laura_data = dict()\n",
    "with open(trainval_path, 'r') as f_in:\n",
    "    for line in f_in:\n",
    "        parts = line.strip().split(',')\n",
    "        laura_data[parts[0]] = [int(elt) for elt in parts[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(laura_data))\n",
    "print(laura_data['000131'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_img, labels in nico_data.items():\n",
    "    laura_labels = laura_data[id_img]\n",
    "    converted = [l if l in [0, 1] else 0 for l in laura_labels]\n",
    "    assert all([converted[i] == labels[i] for i in range(len(labels))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
